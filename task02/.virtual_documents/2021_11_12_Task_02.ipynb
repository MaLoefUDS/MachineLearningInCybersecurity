import time 
 
import numpy as np 
import matplotlib.pyplot as plt 

import json 
import time 
import pickle 
import sys 
import csv 
import os 
import os.path as osp 
import shutil 

import pandas as pd

from IPython.display import display, HTML
 
get_ipython().run_line_magic("matplotlib", " inline ")
plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots 
plt.rcParams['image.interpolation'] = 'nearest' 
plt.rcParams['image.cmap'] = 'gray' 
 
# for auto-reloading external modules 
# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython 
get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")


# Some suggestions of our libraries that might be helpful for this project
from collections import Counter          # an even easier way to count
from multiprocessing import Pool         # for multiprocessing
from tqdm import tqdm                    # fancy progress bars

# Load other libraries here.
# Keep it minimal! We should be easily able to reproduce your code.
# We only support sklearn and pytorch.
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import torch.utils.data as data

# We preload pytorch as an example
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset


compute_mode = 'cpu'

if compute_mode == 'cpu':
    device = torch.device('cpu')
elif compute_mode == 'gpu':
    # If you are using pytorch on the GPU cluster, you have to manually specify which GPU device to use
    # It is extremely important that you *do not* spawn multi-GPU jobs.
    os.environ["CUDA_VISIBLE_DEVICES"] = '0'    # Set device ID here
    device = torch.device('cuda')
else:
    raise ValueError('Unrecognized compute mode')


#
#
# ------- Your Code -------
#
#


# (1)load data

batch_size_train = 64
batch_size_test = 64
n_epochs = 20

transform = transforms.Compose([
    transforms.ToTensor(), # convert the pillow image to tensor
    transforms.Normalize((0.1307, ), (0.3081, )) # normalize
])

train_dataset = datasets.MNIST(root="../dataset/mnist", train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root="../dataset/mnist", train=False, download=True, transform=transform)

train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size_train)
test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size_test)


# (2)define model

class Net(nn.Module):

    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.pooling = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc = nn.Linear(320, 10)

    def forward(self, x):
        x = F.relu(self.pooling(self.conv1(x)))
        x = F.relu(self.pooling(self.conv2(x)))
        x = self.flatten(x)
        x = self.fc(x)
        return x


# (3)define loss, optimizer

model = Net()
criterion = nn.CrossEntropyLoss() # loss function
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)


# (4)train (You can re-use the trained model from project1)

checkpoint = torch.load("CNN_MNIST.pkl")
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']


# (5)evaluate

def test(dataset):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data in dataset:
            images, labels = data
            outputs = model(images)
            _, predicted = torch.max(outputs.data, dim=1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return correct / total


print('Epoch %d, Train acc: %f, Test acc: %f' % (epoch, test(train_loader), test(test_loader)))


def FGSM(X, pertubation, grad):
    sign = grad.sign()
    adv_X = X + (pertubation * sign)
    adv_X = torch.clamp(adv_X, 0, 1)
    return adv_X


execution_times = {}

def create_adversarials(loader, pertubation):
    start = time.time()
    output = list()
    for X, y in loader:
        X.requires_grad = True
        pred = model(X)
        loss = criterion(pred, y)
        model.zero_grad()
        loss.backward()
        grad = X.grad.data
        output.append(FGSM(X, pertubation, grad))
    execution_times[pertubation] = time.time() - start
    return output


# creating 1_000 adversarial images in 10 different levels of pertubation.
# we decided on using 10 versions to better visualize the gradial decent.

pertubations = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

sets = Subset(test_dataset, np.arange(1000))

loader = DataLoader(sets, shuffle=False, batch_size=1)
advs = [create_adversarials(loader, p) for p in pertubations]


# Here we visualize the accuracy achieved by the NN on our sets
# first we create new loaders from our lists of adversarial images


loaders = [[], [], [], [], [], [], [], [], [], []]

labels = test_loader.dataset.test_labels

for i in range(len(advs[0])):
    for idx, loader in enumerate(loaders):
        loader.append((advs[idx][i][0], labels[i]))

loaders = [DataLoader(loaders[idx], shuffle=False, batch_size=batch_size_test) for idx in range(len(loaders))]        


# visualize adversarial images. Same 10 images with different pertubation levels. 

rows, cols = 10, 10
fig, ax = plt.subplots(nrows=rows, ncols=cols)

for i in range(rows):
    for j in range(cols):
        ax[i][j].imshow(advs[i][j].detach().numpy()[0][0])

plt.savefig('fig1.pdf')
plt.show()

plt.figure(figsize=(10,10))
plt.plot(pertubations, [test(loader) for loader in loaders], "*-")
plt.yticks(np.arange(0, 1.1, step=0.1))
plt.xticks(np.arange(0, 1, step=0.1))
plt.xlabel("Pertubation")
plt.ylabel("Accuracy")
plt.savefig('fig2.pdf')
plt.show()


execution_times


#
#
# ------- Your Code -------
#
#



#
#
# ------- Your Code -------
#
#

print('Accuracy on the lower-budget adversarial samples (FGSM) %.2f'%acc_FGSM1)
print('Accuracy on the lower-budget adversarial samples (FGSM) after defense %.2f'%acc_FGSM_defend1)

print('Accuracy on the higher-budget adversarial samples (FGSM) %.2f'%acc_FGSM2)
print('Accuracy on the higher-budget adversarial samples (FGSM) after defense %.2f'%acc_FGSM_defend2)


#
#
# ------- Your Code -------
#
#



#
#
# ------- Your Code -------
#
#



#
#
# ------- Your Code -------
#
#
