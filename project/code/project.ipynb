{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285fbaa5",
   "metadata": {},
   "source": [
    "## Attacking Apples neural hash\n",
    "\n",
    "This notebook will describe a whitebox attack on the underlying neural network of apples neural hash."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the model:\n",
    "Source and Credits: https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./model.onnx\"\n",
    "OUTPUT_MATRIX_PATH = \"./neuralhash_128x96_seed1.dat\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def neural_hash(image):\n",
    "    # Load ONNX model\n",
    "    session = onnxruntime.InferenceSession(MODEL_PATH)\n",
    "\n",
    "    # Load output hash matrix\n",
    "    seed1 = open(OUTPUT_MATRIX_PATH, 'rb').read()[128:]\n",
    "    seed1 = np.frombuffer(seed1, dtype=np.float32)\n",
    "    seed1 = seed1.reshape([96, 128])\n",
    "\n",
    "    # Preprocess image\n",
    "    image = Image.open(image).convert('RGB')\n",
    "    image = image.resize([360, 360])\n",
    "    arr = np.array(image).astype(np.float32) / 255.0\n",
    "    arr = arr * 2.0 - 1.0\n",
    "    arr = arr.transpose(2, 0, 1).reshape([1, 3, 360, 360])\n",
    "\n",
    "    # Run model\n",
    "    inputs = {session.get_inputs()[0].name: arr}\n",
    "    outs = session.run(None, inputs)\n",
    "\n",
    "    # Convert model output to hex hash\n",
    "    hash_output = seed1.dot(outs[0].flatten())\n",
    "    hash_bits = ''.join(['1' if it >= 0 else '0' for it in hash_output])\n",
    "    hash_hex = '{:0{}x}'.format(int(hash_bits, 2), len(hash_bits) // 4)\n",
    "\n",
    "    return hash_hex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "'55d07b72427978ac7a8fd1d9'"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_hash(\"../shrek.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Producing hash collisions\n",
    "Source and Credits: https://github.com/anishathalye/neural-hash-collider"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# util.py\n",
    "\n",
    "import numpy as np\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def load_model(path):\n",
    "    onnx_model = onnx.load(path)\n",
    "    model = prepare(onnx_model, training_mode=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_seed(path):\n",
    "    seed = open(path, 'rb').read()[128:]\n",
    "    seed = np.frombuffer(seed, dtype=np.float32)\n",
    "    seed = seed.reshape([96, 128])\n",
    "    return seed\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    im = Image.open(path).convert('RGB')\n",
    "    im = im.resize([360, 360])\n",
    "    arr = np.array(im).astype(np.float32) / 255.0\n",
    "    arr = arr * 2.0 - 1.0\n",
    "    arr = arr.transpose(2, 0, 1).reshape([1, 3, 360, 360])\n",
    "    return arr\n",
    "\n",
    "\n",
    "def save_image(arr, path):\n",
    "    arr = arr.reshape([3, 360, 360]).transpose(1, 2, 0)\n",
    "    arr = (arr + 1.0) * (255.0 / 2.0)\n",
    "    arr = arr.astype(np.uint8)\n",
    "    im = Image.fromarray(arr)\n",
    "    im.save(path)\n",
    "\n",
    "\n",
    "def hash_from_hex(hex_repr):\n",
    "    n = int(hex_repr, 16)\n",
    "    h = np.zeros(96)\n",
    "    for i in range(96):\n",
    "        h[i] = (n >> (95 - i)) & 1\n",
    "    return h\n",
    "\n",
    "\n",
    "def hash_to_hex(h):\n",
    "    bits = ''.join(['1' if i >= 0.5 else '0' for i in h])\n",
    "    return '{:0{}x}'.format(int(bits, 2), len(bits) // 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# collide.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import os\n",
    "\n",
    "\n",
    "def collide(o_image,\n",
    "            o_model=MODEL_PATH,\n",
    "            o_seed=OUTPUT_MATRIX_PATH,\n",
    "            o_target='59a34eabe31910abfb06f308',\n",
    "            o_learning_rate=2.0,\n",
    "            o_combined_threshold=2,\n",
    "            o_k=10.0,\n",
    "            o_l2_weight=2e-3,\n",
    "            o_tv_weight=1e-4,\n",
    "            o_hash_weight=0.8,\n",
    "            o_clip_range=0.1,\n",
    "            o_iterations=1000,\n",
    "            o_save_directory='.',\n",
    "            o_save_iterations=0,\n",
    "            o_blur=0):\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "    model = load_model(o_model)\n",
    "    image = model.tensor_dict['image']\n",
    "    logits = model.tensor_dict['leaf/logits']\n",
    "    seed = load_seed(o_seed)\n",
    "\n",
    "    target = hash_from_hex(o_target)\n",
    "\n",
    "    original = load_image(o_image)\n",
    "    h = hash_from_hex(o_target)\n",
    "\n",
    "    with model.graph.as_default():\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "            proj = tf.reshape(tf.linalg.matmul(seed, tf.reshape(logits, (128, 1))), (96,))\n",
    "            # proj is in R^96; it's interpreted as a 96-bit hash by mapping\n",
    "            # entries < 0 to the bit '0', and entries >= 0 to the bit '1'\n",
    "            normalized, _ = tf.linalg.normalize(proj)\n",
    "            hash_output = tf.sigmoid(normalized * o_k)\n",
    "            # now, hash_output has entries in (0, 1); it's interpreted by\n",
    "            # mapping entries < 0.5 to the bit '0' and entries >= 0.5 to the\n",
    "            # bit '1'\n",
    "\n",
    "            # we clip hash_output to (clip_range, 1-clip_range); this seems to\n",
    "            # improve the search (we don't \"waste\" perturbation tweaking\n",
    "            # \"strong\" bits); the sigmoid already does this to some degree, but\n",
    "            # this seems to help\n",
    "            hash_output = tf.clip_by_value(hash_output, o_clip_range, 1.0 - o_clip_range) - 0.5\n",
    "            hash_output = hash_output * (0.5 / (0.5 - o_clip_range))\n",
    "            hash_output = hash_output + 0.5\n",
    "\n",
    "            # hash loss: how far away we are from the target hash\n",
    "            hash_loss = tf.math.reduce_sum(tf.math.squared_difference(hash_output, h))\n",
    "\n",
    "            perturbation = image - original\n",
    "            # image loss: how big / noticeable is the perturbation?\n",
    "            img_loss = o_l2_weight * tf.nn.l2_loss(perturbation) + o_tv_weight * tf.image.total_variation(perturbation)[0]\n",
    "\n",
    "            # combined loss: try to minimize both at once\n",
    "            combined_loss = o_hash_weight * hash_loss + (1 - o_hash_weight) * img_loss\n",
    "\n",
    "            # gradients of all the losses\n",
    "            g_hash_loss, = tf.gradients(hash_loss, image)\n",
    "            g_img_loss, = tf.gradients(img_loss, image)\n",
    "            g_combined_loss, = tf.gradients(combined_loss, image)\n",
    "\n",
    "            # perform attack\n",
    "\n",
    "            x = original\n",
    "            best = (float('inf'), 0)  # (distance, image quality loss)\n",
    "            dist = float('inf')\n",
    "\n",
    "            for i in range(o_iterations):\n",
    "                # we do an alternating projections style attack here; if we\n",
    "                # haven't found a colliding image yet, only optimize for that;\n",
    "                # if we have a colliding image, then minimize the size of the\n",
    "                # perturbation; if we're close, then do both at once\n",
    "                if dist == 0:\n",
    "                    loss_name, loss, g = 'image', img_loss, g_img_loss\n",
    "                elif best[0] == 0 and dist <= o_combined_threshold:\n",
    "                    loss_name, loss, g = 'combined', combined_loss, g_combined_loss\n",
    "                else:\n",
    "                    loss_name, loss, g = 'hash', hash_loss, g_hash_loss\n",
    "\n",
    "                # compute loss values and gradient\n",
    "                xq = quantize(x)  # take derivatives wrt the quantized version of the image\n",
    "                hash_output_v, img_loss_v, loss_v, g_v = sess.run([hash_output, img_loss, loss, g], feed_dict={image: xq})\n",
    "                dist = np.sum((hash_output_v >= 0.5) != (h >= 0.5))\n",
    "\n",
    "                # if it's better than any image found so far, save it\n",
    "                score = (dist, img_loss_v)\n",
    "                if score < best or (o_save_iterations > 0 and (i+1) % o_save_iterations == 0):\n",
    "                    save_image(x, os.path.join(o_save_directory, 'out_iter={:05d}_dist={:02d}_q={:.3f}.png'.format(i+1, dist, img_loss_v)))\n",
    "                if score < best:\n",
    "                    best = score\n",
    "\n",
    "                # gradient descent step\n",
    "                g_v_norm = g_v / np.linalg.norm(g_v)\n",
    "                x = x - o_learning_rate * g_v_norm\n",
    "                if o_blur > 0:\n",
    "                    x = blur_perturbation(original, x, o_blur)\n",
    "                x = x.clip(-1, 1)\n",
    "                print('iteration: {}/{}, best: ({}, {:.3f}), hash: {}, distance: {}, loss: {:.3f} ({})'.format(\n",
    "                    i+1,\n",
    "                    o_iterations,\n",
    "                    best[0],\n",
    "                    best[1],\n",
    "                    hash_to_hex(hash_output_v),\n",
    "                    dist,\n",
    "                    loss_v,\n",
    "                    loss_name\n",
    "                ))\n",
    "\n",
    "def quantize(x):\n",
    "    x = (x + 1.0) * (255.0 / 2.0)\n",
    "    x = x.astype(np.uint8).astype(np.float32)\n",
    "    x = x / (255.0 / 2.0) - 1.0\n",
    "    return x\n",
    "\n",
    "\n",
    "def blur_perturbation(original, x, sigma):\n",
    "    perturbation = x - original\n",
    "    perturbation = gaussian_filter_by_channel(perturbation, sigma=sigma)\n",
    "    return original + perturbation\n",
    "\n",
    "\n",
    "def gaussian_filter_by_channel(x, sigma):\n",
    "    return np.stack([gaussian_filter(x[0, ch, :, :], sigma) for ch in range(x.shape[1])])[np.newaxis]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 100/1000, best: (1, 6.297), hash: 1ec173f89d10be5300ac0206, distance: 1, loss: 6.786 (hash)\n",
      "iteration: 200/1000, best: (1, 6.297), hash: 1ec173f89d10be5300ac0206, distance: 1, loss: 6.398 (hash)\n",
      "iteration: 300/1000, best: (1, 6.297), hash: 1ec173f89d10be5300ac0206, distance: 1, loss: 6.329 (hash)\n",
      "iteration: 400/1000, best: (0, 14.153), hash: 1ec173f89d10be5300ac0206, distance: 1, loss: 6.511 (combined)\n",
      "iteration: 500/1000, best: (0, 14.153), hash: 1ec173f89d10be5300ac0206, distance: 1, loss: 6.370 (combined)\n",
      "iteration: 600/1000, best: (0, 14.153), hash: 1ec173f89d10be5300ac0206, distance: 1, loss: 6.340 (combined)\n",
      "iteration: 700/1000, best: (0, 14.153), hash: 1ec173f89d10be5300ac0206, distance: 1, loss: 6.317 (combined)\n",
      "iteration: 800/1000, best: (0, 14.153), hash: 1ec173f89d10be5300ac0206, distance: 1, loss: 6.290 (combined)\n",
      "iteration: 900/1000, best: (0, 14.153), hash: 1ec173f89d10be5300ac0206, distance: 1, loss: 6.280 (combined)\n",
      "iteration: 1000/1000, best: (0, 14.153), hash: 1ec173f89d10be5300ac0206, distance: 1, loss: 6.282 (combined)\n"
     ]
    }
   ],
   "source": [
    "collide(o_image=\"../shrek.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash of doge: 4d3032644e122d8c7326cfc9\n",
      "has of titanic: 1ec173f89d10be5300ac0216\n",
      "hash of pertubated-doge: 1ec173f89d10be5300ac0216\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}